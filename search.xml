<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[MongoDB Data Migration]]></title>
      <url>/2017/09/24/MongoDB-Data-Migrate/</url>
      <content type="html"><![CDATA[<h1 id="MongoDB-Data-Migration"><a href="#MongoDB-Data-Migration" class="headerlink" title="MongoDB Data Migration"></a>MongoDB Data Migration</h1><ul>
<li><p>MongoDB使用json和bson（binary json）格式存储信息。json使用起来非常方便，但是其并不支持bson里的所有数据类型。如果使用json备份数据就会有信息丢失。</p>
</li>
<li><p>备份和恢复MongoDB数据库可能会消耗大量的CPU、内存和磁盘资源，最好是在非高峰期进行。</p>
</li>
<li><p>需要考虑数据一致性的问题。</p>
</li>
</ul>
<a id="more"></a>
<h2 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h2><p>一致性是指事务使得系统从一个一致的状态转换到另一个一致状态。事务的一致性决定了一个系统设计和实现的复杂度。事务可以不同程度的一致性：强一致性：读操作可以立即读到提交的更新操作。弱一致性：提交的更新操作，不一定立即会被读操作读到，此种情况会存在一个不一致窗口，指的是读操作可以读到最新值的一段时间。最终一致性：是弱一致性的特例。事务更新一份数据，最终一致性保证在没有其他事务更新同样的值的话，最终所有的事务都会读到之前事务更新的最新值。如果没有错误发生，不一致窗口的大小依赖于：通信延迟，系统负载等。     其他一致性变体还有：单调一致性：如果一个进程已经读到一个值，那么后续不会读到更早的值。会话一致性：保证客户端和服务器交互的会话过程中，读操作可以读到更新操作后的最新值。</p>
<h2 id="copydb-amp-clone"><a href="#copydb-amp-clone" class="headerlink" title="copydb &amp; clone"></a>copydb &amp; clone</h2><blockquote>
<p>Concurrency</p>
<ul>
<li>copydb and clone do not produce point-in-time snapshots of the source database. Write traffic to the source or destination database during the copy process will result in divergent data sets.</li>
<li>copydb does not lock the destination server during its operation, so the copy will occasionally yield to allow other operations to complete.</li>
<li>clone does not snapshot the database. If any clients update the database you’re copying at any point during the clone operation, the resulting database may be inconsistent.</li>
</ul>
</blockquote>
<p>有数据一致性的问题。</p>
<h2 id="mongodump-amp-mongorestore"><a href="#mongodump-amp-mongorestore" class="headerlink" title="mongodump &amp; mongorestore"></a>mongodump &amp; mongorestore</h2><ul>
<li>以bson格式保存，恢复完成后必须重建索引。</li>
<li>对于小型的数据库是简单高效的备份恢复工具，但是对于大型系统不是一个理想的选择。</li>
<li>mongodump会显著影响MongoDB的性能。如果数据库大小超过系统内存，有可能出现内存不足和页错误。</li>
<li>without –oplog， if there are write operations during the dump operation, the dump will not reflect a single moment in time. Changes made to the database during the update process can affect the output of the backup.</li>
<li>使用oplog可以保证数据一致性</li>
</ul>
<h2 id="master-amp-slave"><a href="#master-amp-slave" class="headerlink" title="master &amp; slave"></a>master &amp; slave</h2><p>slave把master的数据保存在了local.sources collection。迁移完成后需要进一步处理。<br>本质上也是利用了oplog, 可以保证数据一致性。</p>
<h2 id="Replication-Set"><a href="#Replication-Set" class="headerlink" title="Replication Set"></a>Replication Set</h2><p>相当于增强的master slave模式，带有failover机制，多个节点选取一个为主节点，其他为次节点，主节点可读写，次节点只能读，当主节点挂掉会自动选举新的主节点，方便加入新的次节点，扩展数据库系统，本质上也是利用了oplog, 可以保证数据一致性。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>copydb &amp; clone 有数据一致性问题不考虑使用。master &amp; slave模式，slave后续还需要进一步操作，并且官方已不推荐部署此模式。Replication Set提供了很多高级特性，是官方现在推荐的部署模式。处理数据迁移时，master &amp; slave和Replication Set比较接近，前者需要进一步处理，后者配置略麻烦，都相当于自动mongodump + oplogreplay，在数据不是很大的情况下，可以配置一个单节点的Replication Set配合mongodump with oplog比较合适。</p>
<p>oplog有一个非常重要的特性——幂等性（idempotent）。即对一个数据集合，使用oplog中记录的操作重放时，无论被重放多少次，其结果是一样的。举例来说，如果oplog中记录的是一个插入操作，并不会因为你重放了两次，数据库中就得到两条相同的记录。</p>
<p>还有一种方法是使用文件系统提供的快照功能，比如LVM。</p>
<h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p><a href="https://www.digitalocean.com/community/tutorials/how-to-back-up-restore-and-migrate-a-mongodb-database-on-ubuntu-14-04" target="_blank" rel="external">How To Back Up, Restore, and Migrate a MongoDB Database on Ubuntu 14.04</a></p>
<p><a href="https://stackoverflow.com/questions/23688043/migrating-mongodb-instances-with-no-down-time" target="_blank" rel="external">Migrating MongoDB instances with no down-time</a></p>
<p><a href="https://docs.mongodb.com/manual/reference/command/clone/#dbcmd.clone" target="_blank" rel="external">MongoDB Clone</a></p>
<p><a href="https://docs.mongodb.com/manual/reference/command/copydb/#dbcmd.copydb" target="_blank" rel="external">MongoDB Copydb</a></p>
<p><a href="https://docs.mongodb.com/manual/replication/" target="_blank" rel="external">MongoDB Replication</a></p>
<p><a href="https://docs.mongodb.com/manual/core/master-slave/" target="_blank" rel="external">Master Slave Replication</a></p>
]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[Inverted Index in the Luence]]></title>
      <url>/2017/08/29/Inverted-Index-in-the-Luence/</url>
      <content type="html"><![CDATA[<p>假设有一本书，前面有目录，中间是正文，最后会有附录。有这样一种附录，它会把正文中出现的关键名词列出来，并附上正文中出现的页码。当我们想找某个术语的相关信息时，去附录里查正文出现的页码显然方便些。目录类似于我们常规的索引，一个章节/文件里有什么内容；附录保存的信息和它相反，这个信息出现在哪些章节/文件里。我们称附录这种数据的索引方式叫做“Inverted Index”，中文一般翻译为“倒排索引”。<br><a id="more"></a></p>
<p>这种数据结构是搜索程序的核心数据结构，它本身并不复杂，很容易理解，网上的解释也很多，具体可以参考<a href="https://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95" target="_blank" rel="external">维基百科</a>。因为最近接触ElasticSearch，比较好奇它的倒排索引是怎么实现的。</p>
<p><a href="https://en.wikipedia.org/wiki/Elasticsearch" target="_blank" rel="external">ElasticSearch</a>是一个基于<a href="https://zh.wikipedia.org/wiki/Lucene" target="_blank" rel="external">Lucene</a>的全文搜索引擎。Lucene提供了搜索的核心功能，维护倒排索引是其中的功能之一。</p>
<p>Luence的倒排索引是由许多子片段组成的。每一个子片段是一个完整的能独立工作的子索引，由几个二进制文件组成。当有新的文档需要被索引时，会新建子索引，当有文档被删除时，并不会删除对应的索引数据，而是做标记，记录这些数据已经失效了。子索引数据的合并和删除会在某一时间统一执行。</p>
<p>Luence里对数据的基本定义是这样的：</p>
<blockquote>
<p>The fundamental concepts in Lucene are index, document, field and term.</p>
<p>An index contains a sequence of documents.</p>
<ul>
<li><p>A document is a sequence of fields.</p>
</li>
<li><p>A field is a named sequence of terms.</p>
</li>
<li><p>A term is a sequence of bytes.</p>
</li>
</ul>
<p>The same sequence of bytes in two different fields is considered a different term. Thus terms are represented as a pair: the string naming the field, and the bytes within the field.</p>
</blockquote>
<p>所有这些信息都被保存到几个二进制文件里。Lucene为了减少数据的大小，对数据采用了bit packing的压缩方法。举个例子，一个字节可以表示0～127的无符号数，但是如果我们的数据确定最大不会超过63，那就可以只用4位来表示，这样就省去了一半的空间。类似的方法还有ZigZag编码。这部分实现对应代码org.apache.lucene.util.packed。</p>
<p>为了提高搜索效率，Lucene底层查找Term Dictionary(记录了term在文档中的位置信息)时使用了跳跃链表的数据结构。它相对于平衡二叉树简单，但是也有不错的性能，Redies中也有用到。</p>
<h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p><a href="https://www.slideshare.net/lucenerevolution/what-is-inaluceneagrandfinal" target="_blank" rel="external">What is in a Lucene index</a></p>
<p><a href="http://alexbenedetti.blogspot.hk/2015/07/exploring-solr-internals-lucene.html" target="_blank" rel="external">Exploring Solr Internals : The Lucene Inverted Index</a></p>
<p><a href="https://lucene.apache.org/core/6_6_0/core/org/apache/lucene/codecs/lucene62/package-summary.html#package.description" target="_blank" rel="external">Lucene file format</a></p>
<p><a href="http://blog.jpountz.net/post/25530978824/how-fast-is-bit-packing" target="_blank" rel="external">How fast is bit packing</a></p>
<p><a href="https://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8" target="_blank" rel="external">跳跃链表</a></p>
<p><a href="https://developers.google.com/protocol-buffers/docs/encoding" target="_blank" rel="external">ZigZag in ProtoBuffers</a></p>
]]></content>
      
        
    </entry>
    
  
  
    
  
</search>
