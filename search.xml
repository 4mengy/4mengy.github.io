<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MongoDB Data Migration]]></title>
    <url>%2F2017%2F09%2F24%2FMongoDB-Data-Migrate%2F</url>
    <content type="text"><![CDATA[MongoDB使用json和bson（binary json）格式存储信息。json使用起来非常方便，但是其并不支持bson里的所有数据类型。如果使用json备份数据就会有信息丢失。 备份和恢复MongoDB数据库可能会消耗大量的CPU、内存和磁盘资源，最好是在非高峰期进行。 需要考虑数据一致性的问题。 一致性（Consistency）一致性是指事务使得系统从一个一致的状态转换到另一个一致状态。事务的一致性决定了一个系统设计和实现的复杂度。事务可以不同程度的一致性：强一致性：读操作可以立即读到提交的更新操作。弱一致性：提交的更新操作，不一定立即会被读操作读到，此种情况会存在一个不一致窗口，指的是读操作可以读到最新值的一段时间。最终一致性：是弱一致性的特例。事务更新一份数据，最终一致性保证在没有其他事务更新同样的值的话，最终所有的事务都会读到之前事务更新的最新值。如果没有错误发生，不一致窗口的大小依赖于：通信延迟，系统负载等。 其他一致性变体还有：单调一致性：如果一个进程已经读到一个值，那么后续不会读到更早的值。会话一致性：保证客户端和服务器交互的会话过程中，读操作可以读到更新操作后的最新值。 copydb &amp; clone Concurrency copydb and clone do not produce point-in-time snapshots of the source database. Write traffic to the source or destination database during the copy process will result in divergent data sets. copydb does not lock the destination server during its operation, so the copy will occasionally yield to allow other operations to complete. clone does not snapshot the database. If any clients update the database you’re copying at any point during the clone operation, the resulting database may be inconsistent. 有数据一致性的问题。 mongodump &amp; mongorestore 以bson格式保存，恢复完成后必须重建索引。 对于小型的数据库是简单高效的备份恢复工具，但是对于大型系统不是一个理想的选择。 mongodump会显著影响MongoDB的性能。如果数据库大小超过系统内存，有可能出现内存不足和页错误。 without –oplog， if there are write operations during the dump operation, the dump will not reflect a single moment in time. Changes made to the database during the update process can affect the output of the backup. 使用oplog可以保证数据一致性 master &amp; slaveslave把master的数据保存在了local.sources collection。迁移完成后需要进一步处理。本质上也是利用了oplog, 可以保证数据一致性。 Replication Set相当于增强的master slave模式，带有failover机制，多个节点选取一个为主节点，其他为次节点，主节点可读写，次节点只能读，当主节点挂掉会自动选举新的主节点，方便加入新的次节点，扩展数据库系统，本质上也是利用了oplog, 可以保证数据一致性。 总结copydb &amp; clone 有数据一致性问题不考虑使用。master &amp; slave模式，slave后续还需要进一步操作，并且官方已不推荐部署此模式。Replication Set提供了很多高级特性，是官方现在推荐的部署模式。处理数据迁移时，master &amp; slave和Replication Set比较接近，前者需要进一步处理，后者配置略麻烦，都相当于自动mongodump + oplogreplay，在数据不是很大的情况下，可以配置一个单节点的Replication Set配合mongodump with oplog比较合适。 oplog有一个非常重要的特性——幂等性（idempotent）。即对一个数据集合，使用oplog中记录的操作重放时，无论被重放多少次，其结果是一样的。举例来说，如果oplog中记录的是一个插入操作，并不会因为你重放了两次，数据库中就得到两条相同的记录。 还有一种方法是使用文件系统提供的快照功能，比如LVM。 RefHow To Back Up, Restore, and Migrate a MongoDB Database on Ubuntu 14.04 Migrating MongoDB instances with no down-time MongoDB Clone MongoDB Copydb MongoDB Replication Master Slave Replication]]></content>
  </entry>
  <entry>
    <title><![CDATA[Inverted Index in the Luence]]></title>
    <url>%2F2017%2F08%2F29%2FInverted-Index-in-the-Luence%2F</url>
    <content type="text"><![CDATA[假设有一本书，前面有目录，中间是正文，最后会有附录。有这样一种附录，它会把正文中出现的关键名词列出来，并附上正文中出现的页码。当我们想找某个术语的相关信息时，去附录里查正文出现的页码显然方便些。目录类似于我们常规的索引，一个章节/文件里有什么内容；附录保存的信息和它相反，这个信息出现在哪些章节/文件里。我们称附录这种数据的索引方式叫做“Inverted Index”，中文一般翻译为“倒排索引”。 这种数据结构是搜索程序的核心数据结构，它本身并不复杂，很容易理解，网上的解释也很多，具体可以参考维基百科。因为最近接触ElasticSearch，比较好奇它的倒排索引是怎么实现的。 ElasticSearch是一个基于Lucene的全文搜索引擎。Lucene提供了搜索的核心功能，维护倒排索引是其中的功能之一。 Luence的倒排索引是由许多子片段组成的。每一个子片段是一个完整的能独立工作的子索引，由几个二进制文件组成。当有新的文档需要被索引时，会新建子索引，当有文档被删除时，并不会删除对应的索引数据，而是做标记，记录这些数据已经失效了。子索引数据的合并和删除会在某一时间统一执行。 Luence里对数据的基本定义是这样的： The fundamental concepts in Lucene are index, document, field and term. An index contains a sequence of documents. A document is a sequence of fields. A field is a named sequence of terms. A term is a sequence of bytes. The same sequence of bytes in two different fields is considered a different term. Thus terms are represented as a pair: the string naming the field, and the bytes within the field. 所有这些信息都被保存到几个二进制文件里。Lucene为了减少数据的大小，对数据采用了bit packing的压缩方法。举个例子，一个字节可以表示0～127的无符号数，但是如果我们的数据确定最大不会超过63，那就可以只用4位来表示，这样就省去了一半的空间。类似的方法还有ZigZag编码。这部分实现对应代码org.apache.lucene.util.packed。 为了提高搜索效率，Lucene底层查找Term Dictionary(记录了term在文档中的位置信息)时使用了跳跃链表的数据结构。它相对于平衡二叉树简单，但是也有不错的性能，Redies中也有用到。 RefWhat is in a Lucene index Exploring Solr Internals : The Lucene Inverted Index Lucene file format How fast is bit packing 跳跃链表 ZigZag in ProtoBuffers]]></content>
  </entry>
  <entry>
    <title><![CDATA[Valgrind工作原理简介]]></title>
    <url>%2F2016%2F07%2F24%2Fhow-valgrind-work%2F</url>
    <content type="text"><![CDATA[Valgrind是一款用于构建内存调试、内存泄露检测以及性能分析的软件开发框架，它是一个由来自全世界的开发者组织合作开发得到的开源软件。他的初始作者Julian Seward在2006年获得第二届Google-O’Reilly开源代码奖。Valgrind这个名字取自北欧神话中英灵殿的入口。 官方首页上这个骑士与恶龙的绘画由伦敦画家 Rupert Lees 创作。灵感来自于神话传说 St George and the Dragon 。某日，圣乔治到利比亚去，当地沼泽中的一只恶龙（一说鳄鱼）在水泉旁边筑巢，这水泉是Silene城唯一的水源，市民为了取水，每天都要把两头绵羊献祭给恶龙。 到后来，绵羊都吃完了，只好用活人来替代，每天抽签决定何人应选派作牺牲。 有一天，国王的女儿被抽中，国王也没有办法，悲痛欲绝。当少女走近，正要被恶龙吞吃时，圣乔治在这时赶到，提起利矛对抗恶龙，并用腰带把它束缚住，牵到城里当众杀死，救出了公主。 在软件开发过程中我们有时需要追踪程序执行、诊断错误、衡量性能等需求。如果有源代码的话可以添加相应代码，没有源代码时这个方法就行不通了。前者可以对源代码分析，后者只能分析二进制了。我的理解是，dynamic Binary Instrumentation (DBI)强调对二进制执行文件的追踪与信息收集，dynamic Binary Analysis (DBA)强调对收集信息的分析，valgrind是一个DBI框架，使用它可以很方便构建一个DBA工具。 Valgrind作者认为当时的DBI框架都把注意力放在了性能检测上，对程序的质量(原文capabilities)并没有太注意。所以设计了一个新的DBI框架，目标是可以使用它开发重型DBA工具。 Valgrind的重点是shadow values技术，该技术要求对所有的寄存器和使用到的内存做shadow（自己维护一份）。因此使用valgrind开发出来的工具一般跑的都比较慢。为了实现shadow values需要框架实现以下4个部分： Shadow State 提供 shadow registers (例如 integer、FP、SIMD) 提供 shadow memory 读写操作 9个具体功能: instrument read/write instructions instrument read/write system calls Allocation and deallocation operations instrument start-up allocations instrument system call (de)allocations instrument stack (de)allocations instrument heap (de)allocations Transparent execution, but with extra output extra output 核心思想就是要把寄存器和内存中的东西自己维护一份，并且在任何情况下都可以安全正确地使用，同时记录程序的所有操作，在不影响程序执行结果前提下，输出有用的信息。使用shadow values技术的DBI框架都使用不同方式实现了上述全部功能或部分功能。 valgrind结构上分为core和tool，不同的tool具有不同的功能。比较特别的是，valgrind tool都包含core的静态链接，虽然有点浪费空间，但可以简化某些事情。当我们在调用valgrind时，实际上启动的只是一个解析命令参数的启动器，由这个启动器启动具体的tool。 为了实现上述功能，valgrind会利用dynamic binary re-compilation把测试程序（client程序）的机器码解析到VEX中间语言。VEX IR是valgrind开发者专门设计给DBI使用的中间语言，是一种RISC like的语言。目前VEX IR从valgrind分离出去成libVEX了。libVEX采用execution-driven的方式用just-in-time技术动态地把机器码转换为IR，如果发生了某些tool感兴趣的事件，就会hook tool的函数，tool会插入一些分析代码，再把这些代码转换为机器码，存储到code cache中，以便再需要的时候执行。 Machine Code --&gt; IR --&gt; IR --&gt; Machine Code ^ ^ ^ | | | translate | | | | instrument | | translate valgrind启动后，core、tool和client都在一个进程中，共用一个地址空间。core首先会初始化必要的组件，然后载入client，建立client的stack，完成后会要求tool初始化自己，tool完成剩余部分的初始化，这样tool就具有了控制权，开始转换client程式。从某种意义上说，valgrind执行的都是加工后的client程序的代码。 DBI framework 有两种基本的方式可以表示code和进行 instrumentation： disassemble-and-resynthesise (D&amp;R)。Valgrind 使用这种把machine code先转成IR，IR会通过加入更IR来instrument。IR最后转回machine code执行，原本的code对guest state的所有影响都必须明确地转成IR，因为最后执行的是纯粹由IR转成的machine code。 copy-and-annotate (C&amp;A)。instructions会被逐字地复制(除了一些 control flow 改变)每个instruction都加上注解描述其影响(annotate)，利用这些描述来帮助做instrumentation通过给每条指令添加一个额外的data structure (DynamoRIO)通过提供相应的获取指令相关信息的API (Intel Pin)这些添加的注解可以指导进行相应的instrument，并且不影响原来的native code的执行效果。 Ref本文主要参考了官方的研究论文（ http://valgrind.org/docs/pubs.html ）。]]></content>
  </entry>
</search>
